但由于开源大语言模型训练数据有限，因此仍存在知识边界，导致其在垂直领域（如医学、金融、法学等）上的知识不足，进而影响在垂直领域的性能表现。因此，需要进行下游任务适配才能进一步提高其在垂直和细分领域上的性能。主流的下游任务适配方法有两种：a)**上下文学习**；b）**指令微调**
# 1.下游任务适配
## 1.1上下文学习

其实就是利用prompt来辅助模型进行推理
**上下文学习能有效利用大语言模型的能力，但它缺点也很明显**：1）上下文学习的性能和微调依旧存在差距，并且Prompt设计需要花费大量的人力成本，不同Prompt的最终任务性能有较大差异；2）上下文学习虽然完全不需要训练，但在推理阶段的代价会随Prompt中样例的增多快速增加。

## 1.2. 指令微调

指令微调需首先构建指令数据集，然后在该数据集上进行监督微调。
![[Pasted image 20250805084832.png]]
构造这种指令数据一般有**两种方式**：1）数据集成。通过使用模板将带标签的自然语言数据集，转换为指令格式的<输入，输出对。如Flan和P3数据集基于数据集成策略构建；2）大语言模型生成。通过人工收集或者手写少量指令数据，再使用GPT-3.5-Turbo或GPT4等闭源大语言模型进行指令扩展。

**监督微调**：通过上述方法构建完数据集后，可以用完全监督的方式对预训练模型进行微调，在给定指令和输入的情况下，通过顺序预测输出中的每个token来训练模型。经过微调的大语言模型能够显著提升指令遵循（Instruction-following）能力，这有助于增强其推理水平，泛化到新任务和新领域。

# 2 高效微调
但是以上方法占用显存极多，为了减少开销，提出了参数高效微调：主流的PEFT方法可以分为三类：参数附加方法（Additional Parameters Methods），参数选择方法（Parameter Selection Methods）以及低秩适配方法（Low Rank Adaptation Methods）

参数高效微调有以下优势：1)**计算效率高**：PEFT技术减少了需要更新的参数数量，从而降低了训练时的计算资源消耗；2）**存储效率高**：通过减少需要微调的参数数量，PEFT显著降低了微调模型的存储空间，特别适用于内存受限的设备；3）**适应性强**：PEFT能够快速适应不同任务，而无需重新训练整个模型，使得模型在面对变化环境时具有更高的灵活性。
![[Pasted image 20250805091809.png]]
## 2.1 参数附加方法

参数附加方法（AdditionalParameterMethods）通过增加并训练新的附加参数或模块对大语言模型进行微调。参数附加方法按照附加位置可以分为三类：加在输入、加在模型以及加在输出。

### 2.1.1 加在输入

也被叫做软提示Prompt-tuning

换句话说就是在输入之前加上几个刻训练的嵌入。（加上一句固定的话）

就是原先的
$$
 P^{m*d}
$$
变为
$$P^{(n+m)*d}
$$

### 2.1.2 加在模型
加在模型有三种方法：
#### 2.1.2.1 Prefix-tuning

算是Prompt-tuning的升级版本
他在所有的K和V之前都加上了软提示

类似于Prompt-tuning，Prefx-tuning也会面临前缀参数更新不稳定的问题，从而导致优化过程难以收敛。因此，在实际应用中，通常需要在输入Transformer模型前，先通过一个多层感知机（MLP）进行重参数化。这意味着需要训练的参数包括MLP和前缀矩阵两部分。训练完成后，MLP的参数会被丢弃，仅保留前缀参数。（我其实没搞明白这给mlp是怎么运作的）

#### 2.1.2.2 Adapter-tuning

就是在模型的全连接和多头注意力前都加上一层适应层

#### 2.1.2.3 AdapterFusion
换句话说就是我先使用Adapter-tuning训练适应层，然后根据不同的任务挑着用——也就是知识提取

### 2.1.3 加在输出
其实就是更改采样

# 2.2 参数选择方法
参数选择方法（ParameterSelectionMethods）选择性的对预训练模型中的某个参数子集进行微调。和参数附加方法不同的是，参数选择方法无需向模型添加额外的参数，避免了在推理阶段引入额外的计算成本。通常，参数选择方法分为两类：基于规则的方法和基于学习的方法。

### 2.2.1 规则的方法
基于规则的方法根据人类专家的经验，确定哪些参数应该被更新。
就是俺寻思之力！、

### 2.2.2