	Transformer 可以说是现代一切大语言模型的基础，也是大语言模型相关岗位重要的考点。


其中Transformer是基于注意力机制的模块化模型结构
