	Transformer 可以说是现代一切大语言模型的基础，也是大语言模型相关岗位重要的考点。


其中Transformer是基于注意力机制的模块化模型结构
模块包括两种分别是
1、注意力模块
2、全连接前馈模块

两种模块都包含残差结构和正则化模块
区别在于首个模块是注意力模块还是全连接模块

其中，自注意力模块看这个([Transformer结构简谈 - ShaneYale - 博客园](https://www.cnblogs.com/shaneyale/p/18985456))
很直观的解释了位置编码问题和Q，K，V三个值是如何运算的

原始的 Transformer 采用 Encoder-Decoder 架构，其包含 Encoder 和 Decoder 两部分。这两部分都是由自注意力模块和全连接前馈模块重复连接构建而成。其中，Encoder 部分由六个级联的 encoder layer 组成，每个encoder layer 包含一个注意力模块和一个全连接前馈模块。其中的注意力模块为自注意力模块（query，key，value 的输入是相同的）。Decoder 部分由六个级联的decoder layer 组成，每个 decoder layer 包含两个注意力模块和一个全连接前馈模块。其中，第一个注意力模块为自注意力模块，第二个注意力模块为交叉注意力模块
![[Pasted image 20250724154442.png]]
可以很清晰的看到后面的解码器中的q是之前产生的。
在我理解中，在自注意力模块中解码器全部采用X自身产生的q值去×自己和之前的X产生的q值然后累加，来计算相关度，而这里使用的是之前的X的q值，感觉区别在于相互之间的注意力，而非单向的注意力。


transformer也一般使用交叉熵函数作为损失函数


#  1.1 模型采样

换句话说，既然是模型就要有输出，那应该用什么方式进行输出是一个很重要的问题。

模型一般来说输出的只能是词的概率。就像分类模型一样。Transformer也可以视作一种分类模型，他输出的是每一个不同的词的概率。当然区别在于每输出一个词，都会影响之后输出的词的概率，怎么做到全盘考虑也是一个问题。

所以怎么把这种概率转化成文字呢。


## 1.1.1 概率最大化

即输出最有可能的文本，概率可由下式计算，就是每个词的概率的累乘：
$$
P(W_{N+1:N+M}) = \prod_{i=N}^{N+M-1}P[W_{i+1}|W_{1:i}]
$$

而概率最大化应该怎么实现呢？

### 1.1.1.1 贪心
 最大嘛就想到贪心，本来一般来说贪心是会取得最优解，但是这里不现实。因为之前的输出会影响之后的。
 所以贪心会陷入局部最优，这不好。
 
### 1.1.1.2 波束
	（新词啊，没听过）
其实还是贪心，只是放宽了条件的贪心，也就是我取B个最高可能性的词，然后通盘考虑呗，当B=1的时候波束也就变成了贪心了

## 1.1.2 随机采样
	来点创造性啊，你太平庸了Aibo
概率最大化也就意味着最常见——很直接的逻辑。
当我们需要点天马行空的时候，最大概率就不是最好的选择的了。于是我们可以通过随机采样添加随机性
主流的是以下三种：

### 1.1.2.1 Top-K
采样概率最高K个然后随机挑选出结果
但是这种采样有个问题k值不好确定(其实所有带这阵子选择的都有类似的问题)
当K值大而分布方差也大时就会胡言乱语
当K值小而分布方差也小的时候，就会出现和最大概率采样一样的问题，太平庸了

### 1.1.2.2 Top-P 采样
换句话说，从数量约束换成了概率约束，只有概率超过概率值P的才会被算入预测结果中

### 1.1.2.3 Temperature
加了给机制，以应对不同的情况，在需要创造力的时候选取少见的词，反之选取常见的

## 1.2 测评

分为内在和外在

### 1.2.1 内在测评

[[困惑度]]

### 1.2.2 外在测评