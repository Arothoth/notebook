	距离在人工智能中不止直线距离一种，有多种距离，在不同的任务中应该使用不同的距离算法


# 距离度量

那什么样的算法能被定义为距离呢，一般要求满足以下条件：

## 1、非负性
什么叫做非负性呢？就是距离他不可以是一个负数，负的距离还算是距离吗
## 2、同一性
就是到自生的距离为0的点，有且只能由自身而已。
## 3、对称性
同一性是指，对于A，B之间的距离S，你得算出来A到B的距离等于B到A的距离，否则就不对了。来回相等即为对称。
## 4、直递性
$$
dist(x\tiny{i} , \normalsize{x}\tiny{j}) \le \normalsize{} dist (x\tiny{i} , \normalsize{k} \tiny{i}) + \normalsize{}dist (k\tiny{i} , \normalsize{x} \tiny{j})
$$

什么意思呢，在我理解其实这个性质应该叫做路径最短性，换句话说，就是你算出来的A，B距离应该是在这种算法上的最短路径，你无法找到一个A->C->B 的路径距离比直接从A->B还要短，这就是距离的直递性

# 常见距离公式

## 1、欧式距离

这玩意就是最常见的那个,n维度空间中点X到点Y的距离公式如下所示。

$$
\sqrt[2]{\sum_1^n(X\tiny{n}\normalsize{}-Y\tiny{n}\normalsize{})^2}
$$

## 2、标准化欧氏距离 (Standardized EuclideanDistance)
但是欧式距离有个问题在于，向量在各个方向上的分布是不同的，这就导致了有些方向的影响会更大，而有些更小，者不符合我们的要求，所以我们需要标准欧式距离。
$$
\sqrt[2]{\sum_1^n(\frac{X\tiny{n}\normalsize{}-Y\tiny{n}\normalsize{}}{S_n})^2}
$$
其中Sn表示向量在第n维度上的[[标准差]]
这样其实相当于归一化版本的欧式距离

## 3、曼哈顿距离
换句话说这距离就是不能歇着走只能走直线，公式为：
$$
\sum_{i=1}^n|X_i-Y_i|
$$
换句话说就是直接加距离

## 4、切比雪夫距离
这玩意就是只能上下左右直着走或者斜着走，所以距离就是所有维度里最长的那一个。公式为：
$$
max(|X_i-Y_i|), i \in (1,n)
$$

## 5、明可夫斯基距离
这玩意就是以上1，3，4的整合版本，公式为：
$$
\sqrt[p]{\sum_{i = 1}^n(X_i-Y_i)^p}
$$
当p等于1时就是曼哈顿距离
p等于2时就是欧式距离
p等于正无穷时就是切比雪夫距离

## 6、余弦距离
这玩意用来算两个向量夹角的，感觉也蛮有用的，对于向量X(x1,x2,x3....),Y(y1,y2,y3....)由公式如下：

$$
	\frac{\sum_{i=1}^n(xi*yi)}{\sqrt[2]{\sum_{i=1}^nx_i^2}\sqrt[2]{\sum_{i=1}^ny_i^2}}
$$
其实就是遇险公式，两向量相乘，再除以相应的X向量长度和Y向量长度
结果区间在[-1,1]之间，1是代表方向相同，-1代表方向相反，所以使用的时候不能直接以为结果越大距离越远

## 7、编辑距离

即从一个字符串到另外一个字符串所需要经历的增，删，改次数。这种距离通过递归运算实现：


## 8、汉明距离
汉明只允许比较两个相同长度的字符串，他是一个字符串到另一个所需要的最小更改次数。换句话说就是有几位不一样，汉明距离就是多少

## 9、杰卡德距离
杰卡德距离和[[杰卡德相似系数]]恰好相反，不过也对，越相似距离越小，公式为：
$$
1-\frac{A\cap B}{A\cup B}
$$
## 10、马氏距离
这玩意的思路我看懂了，但是运算没看懂，这东西的作用是消除量纲和向量方向的影响，但是怎么做的我没完全看懂，以后有机会再看吧