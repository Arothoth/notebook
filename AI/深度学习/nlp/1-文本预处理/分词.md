# 目录
# 分词算法
分词算法一般又两类，一种是从顶向下，另外一种是从底向上
## 1、自顶向下
原名Top-down (rule-based) tokenization
作用是从最长的开始一点点查有没有和字典中匹配的
从前往后和从后往前进行中文语句分词应该都是这种算法
## 2、自底向上
Byte-PairEncoding: ABottom-upTokenizationAlgorithm
是刚开始只有字母表，然后按照频率，组合将词加入词表


# 分词工具
jieba，是一个常见的中文分词工具，有多种模式和功能


