RNN称为循环神经神经网络
RNN之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。理论上，RNN能够对任何长度的序列数据进行处理。
公式：
$$
S_t=f(U*X_t+W*S_{t-1})
$$
$S_t$是时刻t的输出，$f$是激活函数输入
所以对于输出，不止当前取决于当前输入，还取决于上一个时段的输出，$S_{t-1}$，RNN就所以有了时间上的记忆功能。
RNN每个时刻都会把隐藏层的值存下来，到下一时刻的时候再拿出来用，这样就保证了，每一时刻含有上一时刻的信息

RNN网络分为多种：
1-N
N-N
N-1
N-M
其中，看模型结构N-M一定是最有价值的模型：
# Seq2Seq
也就是N-M模型
这种模型和VAE的思路有些近似，也类似于编码解码的网络
通过N层的RNN网络对于输入数据进行时序的编码，编码结果汇总成为一个向量，然后再通过RNN网络解码输出